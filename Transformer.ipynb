{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of the transformer network\n",
    "\n",
    "d_model = the dimensions of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self,vocab_size,d_model):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size,d_model)\n",
    "    def forward(self,x):\n",
    "        return self.embed(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "class positionalEncoder(nn.Module):\n",
    "    def __init__(self,d_model, max_seq_len = 80):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        pe = torch.zeros(maxlen_seq,d_model)\n",
    "        for pos in range(maxlen):\n",
    "            for i in range(0,d_model,2):\n",
    "                pe[pos,i] = pos / math.sin(10000 ** ((2*i)/d_model))\n",
    "                pe[pos,i+1] = pos / math.cos(10000 ** ((2*(i+1))/d_model))\n",
    "        pe.unsqueeze(0)\n",
    "        self.register_buffer('pe',pe)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + Variable(pe[:,:seq_len],requires_grad=False).cuda()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pos in range(10):\n",
    "#     for i in range(0,10,2):\n",
    "#         print(pos / math.sin(10000 ** ((2*i))/512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_iter))\n",
    "input_seq = batch.English.transpose(0,1)\n",
    "input_pad = EN_TEXT.vocab.stoi['<pad>']\n",
    "# creates mask with 0s wherever there is padding in the input\n",
    "input_msk = (input_seq != input_pad).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask as before\n",
    "target_seq = batch.French.transpose(0,1)\n",
    "target_pad = FR_TEXT.vocab.stoi['<pad>']\n",
    "target_msk = (target_seq != target_pad).unsqueeze(1)\n",
    "size = target_seq.size(1) # get seq_len for matrix\n",
    "nopeak_mask = np.triu(np.ones(1, size, size),\n",
    "k=1).astype('uint8')\n",
    "nopeak_mask = Variable(torch.from_numpy(nopeak_mask) == 0)\n",
    "target_msk = target_msk & nopeak_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4c062158741c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        \n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \n",
    "        bs = q.size(0)\n",
    "        \n",
    "        # perform linear operation and split into h heads\n",
    "        \n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "        \n",
    "        # transpose to get dimensions bs * h * sl * d_model\n",
    "       \n",
    "        k = k.transpose(1,2)\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "# calculate attention using function we will define next\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        \n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1,2).contiguous()\\\n",
    "        .view(bs, -1, self.d_model)\n",
    "        \n",
    "        output = self.out(concat)\n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    \n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "        \n",
    "    output = torch.matmul(scores, v)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n",
    "        super().__init__() \n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps = 1e-6):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.size = d_model\n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
    "        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an encoder layer with one multi-head attention layer and one # feed-forward layer\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.attn = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.ff(x2))\n",
    "        return x\n",
    "    \n",
    "# build a decoder layer with two multi-head attention layers and\n",
    "# one feed-forward layer\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.norm_3 = Norm(d_model)\n",
    "        \n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.attn_1 = MultiHeadAttention(heads, d_model)\n",
    "        self.attn_2 = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model).cuda()\n",
    "def forward(self, x, e_outputs, src_mask, trg_mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs,\n",
    "        src_mask))\n",
    "        x2 = self.norm_3(x)\n",
    "        x = x + self.dropout_3(self.ff(x2))\n",
    "        return x\n",
    "# We can then build a convenient cloning function that can generate multiple layers:\n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self, src, mask):\n",
    "        x = self.embed(src)\n",
    "        x = self.pe(x)\n",
    "        for i in range(N):\n",
    "            x = self.layers[i](x, mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
    "        x = self.embed(trg)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, N, heads)\n",
    "        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n",
    "        self.out = nn.Linear(d_model, trg_vocab)\n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        e_outputs = self.encoder(src, src_mask)\n",
    "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return output\n",
    "# we don't perform softmax on the output as this will be handled \n",
    "# automatically by our loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "heads = 8\n",
    "N = 6\n",
    "src_vocab = len(EN_TEXT.vocab)\n",
    "trg_vocab = len(FR_TEXT.vocab)\n",
    "model = Transformer(src_vocab, trg_vocab, d_model, N, heads)\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "# this code is very important! It initialises the parameters with a\n",
    "# range of values that stops the signal fading or getting too big.\n",
    "# See this blog for a mathematical explanation.\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, print_every=100):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    start = time.time()\n",
    "    temp = start\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "       \n",
    "        for i, batch in enumerate(train_iter):\n",
    "            src = batch.English.transpose(0,1)\n",
    "            trg = batch.French.transpose(0,1)\n",
    "            # the French sentence we input has all words except\n",
    "            # the last, as it is using each word to predict the next\n",
    "            \n",
    "            trg_input = trg[:, :-1]\n",
    "            \n",
    "            # the words we are trying to predict\n",
    "            \n",
    "            targets = trg[:, 1:].contiguous().view(-1)\n",
    "            \n",
    "            # create function to make masks using mask code above\n",
    "            \n",
    "            src_mask, trg_mask = create_masks(src, trg_input)\n",
    "            \n",
    "            preds = model(src, trg_input, src_mask, trg_mask)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            \n",
    "            loss = F.cross_entropy(preds.view(-1, preds.size(-1)),\n",
    "            results, ignore_index=target_pad)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            total_loss += loss.data[0]\n",
    "            if (i + 1) % print_every == 0:\n",
    "                loss_avg = total_loss / print_every\n",
    "                print(\"time = %dm, epoch %d, iter = %d, loss = %.3f,\n",
    "                %ds per %d iters\" % ((time.time() - start) // 60,\n",
    "                epoch + 1, i + 1, loss_avg, time.time() - temp,\n",
    "                print_every)\n",
    "                total_loss = 0\n",
    "                temp = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, src, max_len = 80, custom_string=False):\n",
    "    \n",
    "    model.eval()\n",
    "    if custom_sentence == True:\n",
    "        src = tokenize_en(src)\n",
    "        sentence=\\\n",
    "        Variable(torch.LongTensor([[EN_TEXT.vocab.stoi[tok] for tok\n",
    "        in sentence]])).cuda()\n",
    "    src_mask = (src != input_pad).unsqueeze(-2)\n",
    "    e_outputs = model.encoder(src, src_mask)\n",
    "    \n",
    "    outputs = torch.zeros(max_len).type_as(src.data)\n",
    "    outputs[0] = torch.LongTensor([FR_TEXT.vocab.stoi['<sos>']])\n",
    "    for i in range(1, max_len):    \n",
    "            \n",
    "        trg_mask = np.triu(np.ones((1, i, i),\n",
    "        k=1).astype('uint8')\n",
    "        trg_mask= Variable(torch.from_numpy(trg_mask) == 0).cuda()\n",
    "        \n",
    "        out = model.out(model.decoder(outputs[:i].unsqueeze(0),\n",
    "        e_outputs, src_mask, trg_mask))\n",
    "        out = F.softmax(out, dim=-1)\n",
    "        val, ix = out[:, -1].data.topk(1)\n",
    "        \n",
    "        outputs[i] = ix[0][0]\n",
    "        if ix[0][0] == FR_TEXT.vocab.stoi['<eos>']:\n",
    "            break\n",
    "    return ' '.join(\n",
    "    [FR_TEXT.vocab.itos[ix] for ix in outputs[:i]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the transformer's performance on a time series dataset\n",
    "\n",
    "Taken from http://www.ercot.com/gridinfo/load/load_hist/\n",
    "\n",
    "### The Data\n",
    "\n",
    "- Label: ERCOT. \n",
    "- Use 2018 as test and 2009-2017 as training\n",
    "- Divide ERCOT by 1000\n",
    "- 1hot encode the day of the week\n",
    "- Keep year and hour the same\n",
    "- 11 Features total\n",
    "- Use previous 24 hours to predict the next 12 hours\n",
    "\n",
    "Year,day,hour,load\n",
    "\n",
    "Don't understand how he had 11 features.\n",
    "Going to try with 3 (Month,Day,Hour) and see how that works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/Users/morgan/Code/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010_ERCOT_Hourly_Load_Data.xls\n",
      "2011_ERCOT_Hourly_Load_Data.xls\n",
      "2013_ERCOT_Hourly_Load_Data.xls\n",
      "2009_ERCOT_Hourly_Load_Data.xls\n",
      "2014_ERCOT_Hourly_Load_Data.xls\n",
      "2012_ERCOT_Hourly_Load_Data.xls\n"
     ]
    }
   ],
   "source": [
    "training_set = []\n",
    "test_set = []\n",
    "\n",
    "for excel_file in os.listdir(folder):\n",
    "    if excel_file != '.DS_Store':\n",
    "        print(excel_file)\n",
    "        df = pd.read_excel(folder+'/'+excel_file)\n",
    "        if excel_file == '2014_ERCOT_Hourly_Load_Data.xls':\n",
    "            test_set.append(df)\n",
    "        else:\n",
    "            training_set.append(df)\n",
    "#         df_dict[i] = \n",
    "# self.df_dict = df_dict\n",
    "# df2009 = pd.read_excel('/Users/morgan/Code/Data/2009_ERCOT_Hourly_Load_Data.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.concat(training_set,axis=0)\n",
    "test_df = test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING \n",
      "                  Hour_End        COAST         EAST     FAR_WEST       NORTH  \\\n",
      "0 2010-01-01 01:00:00.003  7775.456846  1238.179861  1237.649967  877.672404   \n",
      "1 2010-01-01 01:59:59.997  7704.815982  1236.050964  1248.907364  883.621724   \n",
      "\n",
      "        NORTH_C     SOUTHERN      SOUTH_C         WEST         ERCOT  \n",
      "0  12405.849409  2467.581039  5031.931981  1059.742927  32094.064435  \n",
      "1  12485.814858  2436.025369  5111.468920  1064.617365  32171.322546  \n",
      "TEST \n",
      "                  Hour_End        COAST         EAST     FAR_WEST       NORTH  \\\n",
      "0 2014-01-01 01:00:00.003  9101.691219  1338.197939  1820.206244  793.458458   \n",
      "1 2014-01-01 01:59:59.997  8907.975782  1328.940064  1809.180861  791.141630   \n",
      "\n",
      "        NORTH_C     SOUTHERN      SOUTH_C         WEST         ERCOT  \n",
      "0  12298.801147  3236.109065  6121.146143  1102.523505  35812.133719  \n",
      "1  12297.109823  3246.493375  6091.018850  1098.774771  35570.635156  \n"
     ]
    }
   ],
   "source": [
    "print('TRAINING \\n',training_df.head(2))\n",
    "print('TEST \\n',test_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43824, 10)\n",
      "(8760, 10)\n"
     ]
    }
   ],
   "source": [
    "print(training_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour_End</th>\n",
       "      <th>COAST</th>\n",
       "      <th>EAST</th>\n",
       "      <th>FAR_WEST</th>\n",
       "      <th>NORTH</th>\n",
       "      <th>NORTH_C</th>\n",
       "      <th>SOUTHERN</th>\n",
       "      <th>SOUTH_C</th>\n",
       "      <th>WEST</th>\n",
       "      <th>ERCOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01 01:00:00.003</td>\n",
       "      <td>7748.160500</td>\n",
       "      <td>878.438488</td>\n",
       "      <td>1289.746813</td>\n",
       "      <td>652.153054</td>\n",
       "      <td>8648.989316</td>\n",
       "      <td>2105.379142</td>\n",
       "      <td>4162.162310</td>\n",
       "      <td>849.000892</td>\n",
       "      <td>26334.030515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01 01:59:59.997</td>\n",
       "      <td>7559.728089</td>\n",
       "      <td>839.092904</td>\n",
       "      <td>1294.272245</td>\n",
       "      <td>643.483530</td>\n",
       "      <td>8553.212708</td>\n",
       "      <td>2047.755534</td>\n",
       "      <td>4070.416593</td>\n",
       "      <td>845.097363</td>\n",
       "      <td>25853.058967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01 03:00:00.000</td>\n",
       "      <td>7337.789042</td>\n",
       "      <td>817.995707</td>\n",
       "      <td>1296.491345</td>\n",
       "      <td>631.940923</td>\n",
       "      <td>8461.317967</td>\n",
       "      <td>1961.909818</td>\n",
       "      <td>3946.994332</td>\n",
       "      <td>840.902848</td>\n",
       "      <td>25295.341984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01 04:00:00.003</td>\n",
       "      <td>7161.895539</td>\n",
       "      <td>814.967883</td>\n",
       "      <td>1297.417294</td>\n",
       "      <td>631.428520</td>\n",
       "      <td>8438.693857</td>\n",
       "      <td>1893.148232</td>\n",
       "      <td>3884.929253</td>\n",
       "      <td>845.452257</td>\n",
       "      <td>24967.932835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01 04:59:59.997</td>\n",
       "      <td>6984.460743</td>\n",
       "      <td>843.952579</td>\n",
       "      <td>1309.534911</td>\n",
       "      <td>640.892563</td>\n",
       "      <td>8565.433348</td>\n",
       "      <td>1867.358425</td>\n",
       "      <td>3911.610238</td>\n",
       "      <td>862.369386</td>\n",
       "      <td>24985.612193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Hour_End        COAST        EAST     FAR_WEST       NORTH  \\\n",
       "0 2012-01-01 01:00:00.003  7748.160500  878.438488  1289.746813  652.153054   \n",
       "1 2012-01-01 01:59:59.997  7559.728089  839.092904  1294.272245  643.483530   \n",
       "2 2012-01-01 03:00:00.000  7337.789042  817.995707  1296.491345  631.940923   \n",
       "3 2012-01-01 04:00:00.003  7161.895539  814.967883  1297.417294  631.428520   \n",
       "4 2012-01-01 04:59:59.997  6984.460743  843.952579  1309.534911  640.892563   \n",
       "\n",
       "       NORTH_C     SOUTHERN      SOUTH_C        WEST         ERCOT  \n",
       "0  8648.989316  2105.379142  4162.162310  849.000892  26334.030515  \n",
       "1  8553.212708  2047.755534  4070.416593  845.097363  25853.058967  \n",
       "2  8461.317967  1961.909818  3946.994332  840.902848  25295.341984  \n",
       "3  8438.693857  1893.148232  3884.929253  845.452257  24967.932835  \n",
       "4  8565.433348  1867.358425  3911.610238  862.369386  24985.612193  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Hour_End.iloc[4].minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate train and test set\n",
    "\n",
    "1 hot encode the day.\n",
    "\n",
    "The minutes need to be checked to round up the hour if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_dayofweek(d,m,y):\n",
    "    t = np.array([0,3,2,5,0,3,5,1,4,6,2,4])\n",
    "    y = np.subtract(y,m<3)\n",
    "    return np.mod(np.add(np.add(np.add(np.subtract(np.add(y,np.divide(y,4).astype(int)),np.divide(y,100).astype(int)),np.divide(y,400).astype(int)),t[m-1]),d),7)\n",
    "\n",
    "def return_ml_inputs(df):\n",
    "    N = df.shape[0]\n",
    "    hours = df.Hour_End.dt.hour\n",
    "    minutes = df.Hour_End.dt.minute\n",
    "    days = df.Hour_End.dt.day\n",
    "    months = df.Hour_End.dt.month\n",
    "    years = df.Hour_End.dt.year\n",
    "    np_months = months.values\n",
    "    np_energy = df.ERCOT.values / 1000\n",
    "    # Increment hour values where minutes are 59\n",
    "    np_minutes = minutes.values\n",
    "    np_hours = hours.values\n",
    "    minute_mask = np.where(np_minutes>0)\n",
    "    np_hours[minute_mask] += 1\n",
    "    # Encode days of the week 0-6\n",
    "    encodedDays = vectorized_dayofweek(days.values,months.values,years.values)\n",
    "    encodedDays = encodedDays[...,None]\n",
    "    np_hours = np_hours[...,None]\n",
    "    np_months = np_months[...,None]\n",
    "    np_energy = np_energy[...,None]\n",
    "    print(encodedDays.shape,np_hours.shape,np_energy.shape,np_months.shape)\n",
    "    ml_inputs = np.concatenate([np_hours,encodedDays,np_months,np_energy],axis=1)\n",
    "    return ml_inputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_N 43824\n",
      "test_N 8760\n"
     ]
    }
   ],
   "source": [
    "training_N = training_df.shape[0]\n",
    "test_N = test_df.shape[0]\n",
    "print('training_N',training_N)\n",
    "print('test_N',test_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43824, 1) (43824, 1) (43824, 1) (43824, 1)\n"
     ]
    }
   ],
   "source": [
    "ml_train = return_ml_inputs(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 1) (8760, 1) (8760, 1) (8760, 1)\n"
     ]
    }
   ],
   "source": [
    "ml_test = return_ml_inputs(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43824, 4)\n",
      "(8760, 4)\n",
      "[ 1.          5.          1.         32.09406444]\n"
     ]
    }
   ],
   "source": [
    "print(ml_train.shape)\n",
    "print(ml_test.shape)\n",
    "print(ml_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "metadata": {},
   "outputs": [],
   "source": [
    "class seqDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, X):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.X = torch.from_numpy(X)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        sample = {'seq': self.X[idx]}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)\n",
    "X_train = ml_train\n",
    "X_test = ml_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43824, 4) (8760, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut up the dataset into chunks of 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatches(data,length):\n",
    "    N = data.shape[0]\n",
    "    print('N',N)\n",
    "    batches = []\n",
    "    for i in range(0,N-length):\n",
    "        batches.append(data[None,i:i+length,:])\n",
    "    return np.vstack(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N 43824\n",
      "N 8760\n"
     ]
    }
   ],
   "source": [
    "Xtrain_batches = get_minibatches(X_train,36)\n",
    "Xtest_batches = get_minibatches(X_test,36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43788, 36, 4)\n",
      "(8724, 36, 4)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain_batches.shape)\n",
    "print(Xtest_batches.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert into dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1315,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = seqDataset(Xtrain_batches)\n",
    "# valset = seqDataset(X_val,y_val)\n",
    "testset = seqDataset(Xtest_batches)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=512,\n",
    "                        shuffle=False, num_workers=4)\n",
    "# valloader = DataLoader(valset, batch_size=512,\n",
    "#                         shuffle=False, num_workers=4)\n",
    "testloader = DataLoader(testset, batch_size=512,\n",
    "                        shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'trainset':trainloader,\n",
    "    'testset':testloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 36, 4])\n"
     ]
    }
   ],
   "source": [
    "d = data_dict['trainset']\n",
    "print(next(iter(d))['seq'].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self,vocab_size,d_model):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size,d_model)\n",
    "    def forward(self,x):\n",
    "        return self.embed(x)\n",
    "\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self,d_model, maxlen_seq = 24):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        pe = torch.zeros(maxlen_seq,d_model)\n",
    "        for pos in range(maxlen_seq):\n",
    "            for i in range(0,d_model,2):\n",
    "                pe[pos,i] = pos / math.sin(10000 ** ((2*i)/d_model))\n",
    "                pe[pos,i+1] = pos / math.cos(10000 ** ((2*(i+1))/d_model))\n",
    "        pe.unsqueeze(0)\n",
    "        self.register_buffer('pe',pe)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + Variable(self.pe[:seq_len,:self.d_model],requires_grad=False)\n",
    "        return x\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        \n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \n",
    "        bs = q.size(0)\n",
    "        \n",
    "        # perform linear operation and split into h heads\n",
    "        \n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "        \n",
    "        # transpose to get dimensions bs * h * sl * d_model\n",
    "       \n",
    "        k = k.transpose(1,2)\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "        # calculate attention using function we will define next\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        \n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1,2).contiguous()\\\n",
    "        .view(bs, -1, self.d_model)\n",
    "        \n",
    "        output = self.out(concat)\n",
    "    \n",
    "        return output\n",
    "    \n",
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    \n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    # No softmax for regression target\n",
    "    # scores = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "        \n",
    "    output = torch.matmul(scores, v)\n",
    "    return output\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n",
    "        super().__init__() \n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "    \n",
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps = 1e-6):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.size = d_model\n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
    "        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm\n",
    "\n",
    "# build an encoder layer with one multi-head attention layer and one # feed-forward layer\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.attn = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.ff(x2))\n",
    "        return x\n",
    "    \n",
    "# build a decoder layer with two multi-head attention layers and\n",
    "# one feed-forward layer\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.norm_3 = Norm(d_model)\n",
    "        \n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.attn_1 = MultiHeadAttention(heads, d_model)\n",
    "        self.attn_2 = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs,\n",
    "        src_mask))\n",
    "        x2 = self.norm_3(x)\n",
    "        x = x + self.dropout_3(self.ff(x2))\n",
    "        return x\n",
    "# We can then build a convenient cloning function that can generate multiple layers:\n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_dict, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embedHour = Embedder(vocab_dict['hour'], 85)\n",
    "        self.embedDay = Embedder(vocab_dict['day'], 85)\n",
    "        self.embedMonth = Embedder(vocab_dict['month'], 85)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self, src, mask):\n",
    "        hour = src[:,:,0].long()\n",
    "        day = src[:,:,1].long()\n",
    "        month = src[:,:,2].long()\n",
    "        target = src[:,:,3].float().unsqueeze(-1)\n",
    "        hour = self.embedHour(hour)\n",
    "        day = self.embedDay(day)\n",
    "        month = self.embedMonth(month)\n",
    "        x = torch.cat((hour,day,month,target),dim=-1)\n",
    "        x = self.pe(x)\n",
    "        for i in range(N):\n",
    "            x = self.layers[i](x, mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_dict, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embedHour = Embedder(vocab_dict['hour'], 85)\n",
    "        self.embedDay = Embedder(vocab_dict['day'], 85)\n",
    "        self.embedMonth = Embedder(vocab_dict['month'], 85)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
    "        hour = trg[:,:,0].long()\n",
    "        day = trg[:,:,1].long()\n",
    "        month = trg[:,:,2].long()\n",
    "        target = trg[:,:,3].float().unsqueeze(-1)\n",
    "        hour = self.embedHour(hour)\n",
    "        day = self.embedDay(day)\n",
    "        month = self.embedMonth(month)\n",
    "        x = torch.cat((hour,day,month,target),dim=-1)\n",
    "        x = self.pe(x)\n",
    "#         print('src_mask, trg_mask',src_mask.size(), trg_mask.size())\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, e_outputs, src_mask, trg_mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, N, heads)\n",
    "        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n",
    "        self.out = nn.Linear(d_model, 1)\n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        e_outputs = self.encoder(src, src_mask)\n",
    "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return output\n",
    "# we don't perform softmax on the output as this will be handled \n",
    "# automatically by our loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the transformer\n",
    "\n",
    "- src = the previous 24 hour data\n",
    "- trg = the next 12 hour data\n",
    "- src_mask = the zero'd out triangle of the src matrix\n",
    "- trg_mask = the zero'd out triangle of the trg matrix\n",
    "\n",
    "src should look like (M,24,4)\n",
    "and target like (M,12,4)\n",
    "\n",
    "Teacher forcing is taking the desired result of the decoder and inputting that into the next layer, instead of using the output from the network during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 256\n",
    "N = 2\n",
    "heads = 8\n",
    "vocab_dict = {'hour':25,'day':7,'month':13}\n",
    "\n",
    "test_net = Transformer(vocab_dict,vocab_dict, d_model, N, heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 36, 4])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 24, 4]' is invalid for input of size 3456",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1294-e17f7be9fdb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_trg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest_trg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_trg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 24, 4]' is invalid for input of size 3456"
     ]
    }
   ],
   "source": [
    "data = next(iter(data_dict['trainset']))\n",
    "print(data['seq'].size())\n",
    "test_src = data['seq'][:24]\n",
    "test_trg = data['seq'][24:]\n",
    "test_src = test_src.view(1,24,4)\n",
    "test_trg = test_trg.view(1,12,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask the inputs\n",
    "\n",
    "There is no padding for the target so we don't need to mask the padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 36, 4]) torch.Size([2024, 36, 4])\n"
     ]
    }
   ],
   "source": [
    "print(test_src.shape,test_trg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_msk = torch.ones((1,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "torch.Size([1, 12, 12])\n",
      "tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "size = test_trg.shape[1] # get seq_len for matrix\n",
    "print(size)\n",
    "nopeak_mask = np.triu(np.ones((1,size, size)),k=1).astype('uint8')\n",
    "# nopeak_mask = np.triu(np.ones(1, size, size),k=1).astype('uint8')\n",
    "nopeak_mask = Variable(torch.from_numpy(nopeak_mask) == 0)\n",
    "# target_msk = target_msk & nopeak_mask\n",
    "print(nopeak_mask.shape)\n",
    "print(nopeak_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.zeros([1,8,12,24])\n",
    "# m = torch.ones([1,1,12,12])\n",
    "# a = a.masked_fill(m == 0, -1e9)\n",
    "# print(a.size())\n",
    "# torch.matmul(a, torch.ones((1, 8, 12, 24))).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 85]) torch.Size([1, 24, 85]) torch.Size([1, 24, 85]) torch.Size([1, 24, 1])\n",
      "x torch.Size([1, 24, 256])\n",
      "k,q,v torch.Size([1, 8, 24, 32]) torch.Size([1, 8, 24, 32]) torch.Size([1, 8, 24, 32])\n",
      "attention,scores,msk torch.Size([1, 8, 24, 24]) torch.Size([1, 1, 24])\n",
      "scores, v torch.Size([1, 8, 24, 24]) torch.Size([1, 8, 24, 32])\n",
      "k,q,v torch.Size([1, 8, 24, 32]) torch.Size([1, 8, 24, 32]) torch.Size([1, 8, 24, 32])\n",
      "attention,scores,msk torch.Size([1, 8, 24, 24]) torch.Size([1, 1, 24])\n",
      "scores, v torch.Size([1, 8, 24, 24]) torch.Size([1, 8, 24, 32])\n",
      "e_outputs torch.Size([1, 24, 256])\n",
      "torch.Size([1, 12, 85]) torch.Size([1, 12, 85]) torch.Size([1, 12, 85]) torch.Size([1, 12, 1])\n",
      "x torch.Size([1, 12, 256])\n",
      "dx torch.Size([1, 12, 256])\n",
      "k,q,v torch.Size([1, 8, 12, 32]) torch.Size([1, 8, 12, 32]) torch.Size([1, 8, 12, 32])\n",
      "attention,scores,msk torch.Size([1, 8, 12, 12]) torch.Size([1, 1, 12, 12])\n",
      "scores, v torch.Size([1, 8, 12, 12]) torch.Size([1, 8, 12, 32])\n",
      "k,q,v torch.Size([1, 8, 24, 32]) torch.Size([1, 8, 12, 32]) torch.Size([1, 8, 24, 32])\n",
      "attention,scores,msk torch.Size([1, 8, 12, 24]) torch.Size([1, 1, 24])\n",
      "scores, v torch.Size([1, 8, 12, 24]) torch.Size([1, 8, 24, 32])\n",
      "k,q,v torch.Size([1, 8, 12, 32]) torch.Size([1, 8, 12, 32]) torch.Size([1, 8, 12, 32])\n",
      "attention,scores,msk torch.Size([1, 8, 12, 12]) torch.Size([1, 1, 12, 12])\n",
      "scores, v torch.Size([1, 8, 12, 12]) torch.Size([1, 8, 12, 32])\n",
      "k,q,v torch.Size([1, 8, 24, 32]) torch.Size([1, 8, 12, 32]) torch.Size([1, 8, 24, 32])\n",
      "attention,scores,msk torch.Size([1, 8, 12, 24]) torch.Size([1, 1, 24])\n",
      "scores, v torch.Size([1, 8, 12, 24]) torch.Size([1, 8, 24, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9353],\n",
       "         [-1.1473],\n",
       "         [-1.0982],\n",
       "         [-1.0403],\n",
       "         [-1.0347],\n",
       "         [-1.1327],\n",
       "         [-1.2930],\n",
       "         [-1.1993],\n",
       "         [-1.2835],\n",
       "         [-1.1091],\n",
       "         [-0.7600],\n",
       "         [ 0.1165]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 1033,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_net(test_src,test_trg,src_msk,nopeak_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the transformer on regression sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(src_len,trg_len,batch_size):\n",
    "    src_mask = torch.ones([batch_size,1,src_len])\n",
    "    nopeak_mask = np.triu(np.ones((batch_size, trg_len, trg_len)),k=1).astype('uint8')\n",
    "    nopeak_mask = Variable(torch.from_numpy(nopeak_mask) == 0)\n",
    "    return src_mask,nopeak_mask\n",
    "\n",
    "def train_energy(model,data_dict,train_params):\n",
    "    start_time = time.time()\n",
    "    scores_window = deque(maxlen=100)\n",
    "    scores = []\n",
    "    for e in range(train_params['epochs']):\n",
    "        for i, data in enumerate(data_dict['trainset'], 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            src = data['seq'][:,:24,:]\n",
    "            trg = data['seq'][:,24:,:]\n",
    "            src_mask,trg_mask = create_masks(24,12,train_params['batch_size'])\n",
    "            preds = model(src,trg,src_mask,trg_mask)\n",
    "            y = trg[:,:,-1].float()\n",
    "            optim.zero_grad()\n",
    "            loss = train_params['criterion'](preds.squeeze(-1),y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            scores_window.append(loss.data)\n",
    "            scores.append(np.mean(scores_window))\n",
    "            if (i + 1) % train_params['print_every'] == 0:\n",
    "                loss_avg = np.mean(scores_window)\n",
    "                print(\"time = %dm, epoch %d, iter = %d, loss = %.3f,%ds per %d iters\" % \n",
    "                      ((time.time() - start_time) // 60,e + 1, i + 1, loss_avg, time.time() - start_time,\n",
    "                train_params['print_every']))\n",
    "            if i == train_params['episodes']:\n",
    "                break\n",
    "    return model,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 256\n",
    "N = 2\n",
    "heads = 8\n",
    "vocab_dict = {'hour':25,'day':7,'month':13}\n",
    "\n",
    "energy_model = Transformer(vocab_dict,vocab_dict, d_model, N, heads)\n",
    "\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optim = torch.optim.Adam(energy_model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "train_params = {\n",
    "    'epochs':10,\n",
    "    'episodes':10,\n",
    "    'optimizer':optim,\n",
    "    'criterion': criterion,\n",
    "    'print_every':5,\n",
    "    'batch_size':512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.zeros([2048, 8, 24, 24])\n",
    "# m = torch.ones([2048, 1,1, 24])\n",
    "# a = a.masked_fill(m == 0, -1e9)\n",
    "# print(a.size())\n",
    "# # torch.matmul(a, torch.ones((1, 8, 12, 24))).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 0m, epoch 1, iter = 5, loss = 31.458,26s per 5 iters\n",
      "time = 0m, epoch 1, iter = 10, loss = 34.154,50s per 5 iters\n",
      "time = 1m, epoch 2, iter = 5, loss = 32.651,78s per 5 iters\n",
      "time = 1m, epoch 2, iter = 10, loss = 32.908,101s per 5 iters\n",
      "time = 2m, epoch 3, iter = 5, loss = 31.825,130s per 5 iters\n",
      "time = 2m, epoch 3, iter = 10, loss = 31.903,155s per 5 iters\n",
      "time = 3m, epoch 4, iter = 5, loss = 31.139,183s per 5 iters\n",
      "time = 3m, epoch 4, iter = 10, loss = 31.194,208s per 5 iters\n",
      "time = 3m, epoch 5, iter = 5, loss = 30.617,237s per 5 iters\n",
      "time = 4m, epoch 5, iter = 10, loss = 30.660,260s per 5 iters\n",
      "time = 4m, epoch 6, iter = 5, loss = 30.191,299s per 5 iters\n",
      "time = 5m, epoch 6, iter = 10, loss = 30.219,340s per 5 iters\n",
      "time = 6m, epoch 7, iter = 5, loss = 29.811,374s per 5 iters\n",
      "time = 6m, epoch 7, iter = 10, loss = 29.819,402s per 5 iters\n",
      "time = 7m, epoch 8, iter = 5, loss = 29.450,435s per 5 iters\n",
      "time = 7m, epoch 8, iter = 10, loss = 29.446,462s per 5 iters\n",
      "time = 8m, epoch 9, iter = 5, loss = 29.115,496s per 5 iters\n",
      "time = 8m, epoch 9, iter = 10, loss = 29.109,523s per 5 iters\n",
      "time = 9m, epoch 10, iter = 5, loss = 28.665,554s per 5 iters\n",
      "time = 9m, epoch 10, iter = 10, loss = 28.393,582s per 5 iters\n"
     ]
    }
   ],
   "source": [
    "trained_model,scores = train_energy(energy_model,data_dict,train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(23.9601)\n",
      "loss tensor(23.4613)\n",
      "loss tensor(21.7237)\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(data_dict['trainset'], 0):\n",
    "    src = data['seq'][:,:24,:]\n",
    "    trg = data['seq'][:,24:,:]\n",
    "    src_mask,trg_mask = create_masks(24,12,train_params['batch_size'])\n",
    "    preds = trained_model(src,trg,src_mask,trg_mask)\n",
    "    y = trg[:,:,-1].float()\n",
    "    loss = train_params['criterion'](preds.squeeze(-1),y)\n",
    "    print('loss',loss.data)\n",
    "#     print('pred y',preds,y)\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot energy consumption and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3d2ba208>]"
      ]
     },
     "execution_count": 1333,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the transformer on language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_iter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-680-5c297579a4e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnglish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEN_TEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<pad>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_iter' is not defined"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "input_seq = batch.English.transpose(0,1)\n",
    "input_pad = EN_TEXT.vocab.stoi['<pad>']\n",
    "# creates mask with 0s wherever there is padding in the input\n",
    "input_msk = (input_seq != input_pad).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask as before\n",
    "target_seq = batch.French.transpose(0,1)\n",
    "target_pad = FR_TEXT.vocab.stoi['<pad>']\n",
    "target_msk = (target_seq != target_pad).unsqueeze(1)\n",
    "size = target_seq.size(1) # get seq_len for matrix\n",
    "nopeak_mask = np.triu(np.ones(1, size, size),k=1).astype('uint8')\n",
    "nopeak_mask = Variable(torch.from_numpy(nopeak_mask) == 0)\n",
    "target_msk = target_msk & nopeak_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "heads = 8\n",
    "N = 6\n",
    "src_vocab = len(EN_TEXT.vocab)\n",
    "trg_vocab = len(FR_TEXT.vocab)\n",
    "model = Transformer(src_vocab, trg_vocab, d_model, N, heads)\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "# this code is very important! It initialises the parameters with a\n",
    "# range of values that stops the signal fading or getting too big.\n",
    "# See this blog for a mathematical explanation.\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, print_every=100):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    start = time.time()\n",
    "    temp = start\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "       \n",
    "        for i, batch in enumerate(train_iter):\n",
    "            src = batch.English.transpose(0,1)\n",
    "            trg = batch.French.transpose(0,1)\n",
    "            # the French sentence we input has all words except\n",
    "            # the last, as it is using each word to predict the next\n",
    "            \n",
    "            trg_input = trg[:, :-1]\n",
    "            \n",
    "            # the words we are trying to predict\n",
    "            \n",
    "            targets = trg[:, 1:].contiguous().view(-1)\n",
    "            \n",
    "            # create function to make masks using mask code above\n",
    "            \n",
    "            src_mask, trg_mask = create_masks(src, trg_input)\n",
    "            \n",
    "            preds = model(src, trg_input, src_mask, trg_mask)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            \n",
    "            loss = F.cross_entropy(preds.view(-1, preds.size(-1)),\n",
    "            results, ignore_index=target_pad)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            total_loss += loss.data[0]\n",
    "            if (i + 1) % print_every == 0:\n",
    "                loss_avg = total_loss / print_every\n",
    "                print(\"time = %dm, epoch %d, iter = %d, loss = %.3f,\n",
    "                %ds per %d iters\" % ((time.time() - start) // 60,\n",
    "                epoch + 1, i + 1, loss_avg, time.time() - temp,\n",
    "                print_every))\n",
    "                total_loss = 0\n",
    "                temp = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
