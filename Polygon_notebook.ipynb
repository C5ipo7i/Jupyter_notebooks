{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polygon import RESTClient\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from random import randrange\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'59.35' u'58.835' u'59.5539' u'58.615' u'1881167.0'\n",
      "  u'2019-12-30T03:30:00Z']\n",
      " [u'58.85' u'59.08' u'59.355' u'58.65' u'1732381.0'\n",
      "  u'2019-12-31T03:30:00Z']]\n"
     ]
    }
   ],
   "source": [
    "test = np.load('/media/shuza/HDD_Toshiba/Datasets/snapshots/ATVI/2019.npy') \n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Polygon(object):\n",
    "    def __init__(self,API_KEY):\n",
    "        self.key = API_KEY\n",
    "        self.client = RESTClient(self.key)\n",
    "        self.domain = 'https://api.polygon.io/v2'\n",
    "    \n",
    "    def get_news(self,symbol):\n",
    "        resp = self.client.reference_ticker_news(symbol)\n",
    "        return resp\n",
    "    \n",
    "    def get_ticks(self,params):\n",
    "        symbol,date,timestamp,timestampLimit,limit = params.values()\n",
    "        tick_url = f'{self.domain}/ticks/stocks/trades/{symbol}/{date}?timestamp={timestamp}&timestampLimit={timestampLimit}&limit={limit}&apiKey={self.key}'\n",
    "        print('tick_url',tick_url)\n",
    "        r = requests.get(tick_url)\n",
    "        ticks = r.json()\n",
    "        return ticks\n",
    "    \n",
    "    def get_day_trades(self,symbol,start_date,unix_day_start,unix_day_end):\n",
    "        results = []\n",
    "#         elapsed_from_start = 0\n",
    "        start_time = unix_day_start\n",
    "        while True:\n",
    "            print('elapsed_from_start',start_time - unix_day_start)\n",
    "            params = {'symbol':symbol,'date':start_date,'timestamp':start_time,'timestampLimit':unix_day_end,'limit':50000}\n",
    "            ticks = self.get_ticks(params)\n",
    "            data = Polygon.store_data(ticks)\n",
    "            if data.size > 0:\n",
    "                results.append(data)\n",
    "            if 'results' in ticks:\n",
    "                if len(ticks['results']) < 50000:\n",
    "                    break\n",
    "                # Get new start\n",
    "                temp = datetime.fromtimestamp(int(str(int(data[-1,0]))[:-9]))\n",
    "                start_time = int(1e+9*(temp.timestamp()))\n",
    "            else:\n",
    "                break\n",
    "        if len(results) > 0:\n",
    "            results = np.concatenate(results)\n",
    "        else:\n",
    "            results = np.array([])\n",
    "        return results\n",
    "        \n",
    "\n",
    "    def get_range(self,symbol,start_date,end_date,symbol_path):\n",
    "        \"\"\"\n",
    "        symbol : string\n",
    "        start_date : string date\n",
    "        end_date : string date\n",
    "        \"\"\"\n",
    "        time_diff = datetime.strptime(end_date,'%Y-%m-%d') - datetime.strptime(start_date,'%Y-%m-%d')\n",
    "        print(f'start date {start_date},end date {end_date},time span of {time_diff}')\n",
    "        results = []\n",
    "        i = 1\n",
    "        while start_date != end_date:\n",
    "            print('date',start_date)\n",
    "#             start_time = datetime.strptime(start_date,'%Y-%m-%d') + timedelta(hours=9) + timedelta(minutes=30)\n",
    "            temp_start = datetime.strptime(start_date,'%Y-%m-%d') + timedelta(hours=9) + timedelta(minutes=30)\n",
    "            temp_end = datetime.strptime(start_date,'%Y-%m-%d') + timedelta(hours=16)\n",
    "            unix_day_start = int(1e+9*(temp_start.timestamp()))\n",
    "            unix_day_end = int(1e+9*(temp_end.timestamp()))\n",
    "\n",
    "            day_trades = self.get_day_trades(symbol,start_date,unix_day_start,unix_day_end)\n",
    "            print('day_trades.shape',day_trades.shape)\n",
    "            if day_trades.size > 0:\n",
    "                np.save(symbol_path+f'/{start_date}',day_trades)\n",
    "                results.append(day_trades)\n",
    "            start_date = datetime.strptime(start_date,'%Y-%m-%d')\n",
    "            start_date = str((start_date + timedelta(days=1)).date())\n",
    "            \n",
    "            if i > 100:\n",
    "                print('loop break')\n",
    "                break\n",
    "            i += 1\n",
    "        return results\n",
    "    \n",
    "    @staticmethod\n",
    "    def store_data(ticks):\n",
    "        if 'results' in ticks:\n",
    "            print('num results',len(ticks['results']))\n",
    "            data = np.empty((len(ticks['results']),3))\n",
    "            for i,result in enumerate(ticks['results']):\n",
    "                data[i,0] = result['t']\n",
    "                data[i,1] = result['s']\n",
    "                data[i,2] = result['p']\n",
    "        else:\n",
    "            data = np.array([])\n",
    "        return data\n",
    "    \n",
    "    def get_symbol_data(self,symbol_list,start,end,num_samples,folder):\n",
    "        \"\"\"\n",
    "        symbol_list : list\n",
    "        start : datetime object\n",
    "        end : datetime object\n",
    "        num_samples : int\n",
    "        \"\"\"\n",
    "        stock_data = {}\n",
    "        for symbol in symbol_list:\n",
    "            symbol_results = []\n",
    "            symbol_path = os.path.join(folder,str(symbol))\n",
    "            if not os.path.isdir(symbol_path):\n",
    "                os.mkdir(symbol_path)\n",
    "            for _ in range(num_samples):\n",
    "                random_start_date = random_date(start,end)\n",
    "                start_date = datetime.strptime(str(random_start_date.date()),'%Y-%m-%d')\n",
    "                \n",
    "                string_start_date = str(start_date.date())\n",
    "                string_end_date = str((start_date + timedelta(days=1)).date())\n",
    "                \n",
    "                results = self.get_range(symbol,string_start_date,string_end_date,symbol_path)\n",
    "                symbol_results.append(results)\n",
    "            # To store data in dict\n",
    "            # stock_data[symbol] = symbol_results\n",
    "            # TO store data in file\n",
    "        return stock_data\n",
    "    \n",
    "    def get_ticker_names(self,params):\n",
    "        \"\"\"\n",
    "        number of tickers : 24852\n",
    "        max perpage : 50\n",
    "        number of pages needed to traverse entire list : 498\n",
    "        start_page : 1 - 497\n",
    "        end_page : 2 - 498\n",
    "        \"\"\"\n",
    "        assert min(max(params['start_page'],1),497) == params['start_page']\n",
    "        assert min(max(params['end_page'],2),498) == params['end_page']\n",
    "        market = params[\"market\"]\n",
    "        locale = params[\"locale\"]\n",
    "        perpage = params[\"perpage\"]\n",
    "        active = params[\"active\"]\n",
    "        symbol_arr = np.array([])\n",
    "        for page in range(params['start_page'],params['end_page']+1):\n",
    "            url = f'{self.domain}/reference/tickers?sort=ticker&market={market}&locale={locale}&perpage={perpage}&page={page}&active={active}&apiKey={self.key}'\n",
    "            r = requests.get(url)\n",
    "            data = r.json()\n",
    "            stock_names = [stock['ticker'] for stock in data['tickers']]\n",
    "            symbol_arr = np.hstack((symbol_arr,np.array(stock_names)))\n",
    "                \n",
    "        return symbol_arr\n",
    "        \n",
    "    \n",
    "    def get_snapshot(self,symbol,start_date,end_date):\n",
    "        \"\"\"\n",
    "        symbol : string\n",
    "        start_date : string date\n",
    "        end_date : string date\n",
    "        \"\"\"\n",
    "        time_diff = datetime.strptime(end_date,'%Y-%m-%d') - datetime.strptime(start_date,'%Y-%m-%d')\n",
    "        assert time_diff.days > 0\n",
    "        print(f'start date {start_date},end date {end_date},time span of {time_diff}')\n",
    "        results = []\n",
    "        while start_date != end_date:\n",
    "            print('start_date',start_date)\n",
    "            url = f'https://api.polygon.io/v1/open-close/{symbol}/{start_date}?apiKey={self.key}'\n",
    "            r = requests.get(url)\n",
    "            data = r.json()\n",
    "            start_date = str((datetime.strptime(start_date,'%Y-%m-%d') + timedelta(days=1)).date())\n",
    "            if data['status'] == 'OK':\n",
    "                results.append(data)\n",
    "        return results\n",
    "              \n",
    "    def get_symbol_snapshots(self,symbol_list,start,end):\n",
    "        \"\"\"\n",
    "        symbol_list : list\n",
    "        start : date string %Y-%m-%d\n",
    "        end : date string %Y-%m-%d\n",
    "        \"\"\"\n",
    "        stock_data = {}\n",
    "        for symbol in symbol_list:\n",
    "            symbol_results = []\n",
    "            results = self.get_snapshot(symbol,start,end)\n",
    "            stock_data[symbol] = results\n",
    "        return stock_data\n",
    "        \n",
    "def random_date(start, end):\n",
    "    \"\"\"\n",
    "    This function will return a random datetime between two datetime \n",
    "    objects.\n",
    "    \"\"\"\n",
    "    delta = end - start\n",
    "    int_delta = (delta.days * 24 * 60 * 60) + delta.seconds\n",
    "    random_second = randrange(int_delta)\n",
    "    return start + timedelta(seconds=random_second)           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert API key here\n",
    "API_KEY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = Polygon(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get list of tickers to get data for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'perpage': 50,\n",
    "    'locale': 'us',\n",
    "    'market': 'STOCKS',\n",
    "    'active': 'true',\n",
    "    'start_page': 1,\n",
    "    'end_page':4\n",
    "}\n",
    "tickers = interface.get_ticker_names(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ticker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime(year, month, day, hour, minute, second, microsecond)\n",
    "start = datetime(2017, 1, 1, 0, 0, 0, 0)\n",
    "# datetime(year, month, day, hour, minute, second, microsecond)\n",
    "end = datetime(2020, 1, 1, 0, 0, 0, 0)\n",
    "start_date = str((start.date()))\n",
    "end_date = str(end.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_list = ['TSLA','AAPL']\n",
    "num_samples = 5\n",
    "folder = '/Users/morgan/Code/Jupyter_notebooks/market_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = interface.get_symbol_data(symbol_list,start,end,num_samples,folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_x(data):\n",
    "    X = np.array([])\n",
    "    for sample in data:\n",
    "        print(sample,len(sample[0]))\n",
    "        if len(sample[0]) == 0:\n",
    "            continue\n",
    "        sample_X = sample[0][0][:,2]\n",
    "        if X.size == 0:\n",
    "            X = sample_X\n",
    "        else:\n",
    "            X = np.hstack((X,sample_X))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_results = results['TSLA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tesla_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = extract_x(tesla_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = results[0][0]\n",
    "print(datetime.fromtimestamp(int(str(int(data[0,0]))[:-9])))\n",
    "print(datetime.fromtimestamp(int(str(int(data[-1,0]))[:-9])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "string_date = datetime.strptime('2018-02-01','%Y-%m-%d')\n",
    "print(string_date)\n",
    "test_date = datetime.fromtimestamp(int(str(int(data[0,0]))[:-9]))\n",
    "print(test_date)\n",
    "test_date += timedelta(days=1)\n",
    "print(test_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = interface.get_news('tsla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resp.news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "sources = []\n",
    "times = []\n",
    "for i,new in enumerate(news):\n",
    "#     print(dir(new))\n",
    "#     print(new.title)\n",
    "#     print(new.summary)\n",
    "#     print(new.source)\n",
    "#     print(new.keywords)\n",
    "#     print(new.image)\n",
    "#     print(new.timestamp)\n",
    "    content.append(new.summary)\n",
    "    sources.append(new.source)\n",
    "    times.append(new.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tick Data\n",
    " \n",
    "- Timestamp -t\n",
    "- size -s\n",
    "- price -p\n",
    "\n",
    "Sequentially get the tick data up to a certain time.\n",
    "\n",
    "### Params\n",
    "- start time\n",
    "- end time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = date(2019, 4, 13)\n",
    "end_time = date(2020,1,1)\n",
    "# datetime(year, month, day, hour, minute, second, microsecond)\n",
    "b = datetime(2017, 11, 28, 23, 55, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.empty((50000,3))\n",
    "for i,result in enumerate(ticks['results']):\n",
    "    data[i,0] = result['t']\n",
    "    data[i,1] = result['s']\n",
    "    data[i,2] = result['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0,0] - data[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(int(data[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(str(int(data[0,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = str(int(data[0,0]))[:-9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.fromtimestamp(int(str(int(data[0,0]))[:-9])))\n",
    "print(datetime.fromtimestamp(int(str(int(data[-1,0]))[:-9])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.fromtimestamp(int(str(int(data[0,0]))[:-9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(str(1577944970))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.fromtimestamp(1577944970)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.utcfromtimestamp(int(data[0,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_object = datetime.utcfromtimestamp(int(data[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[-10:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = tickers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_names = tickers['tickers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [name['ticker'] for name in ticker_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_nasdaq = [\n",
    "'ATVI',\n",
    "'ADBE',\n",
    "'AMD',\n",
    "'ALXN',\n",
    "'ALGN',\n",
    "'GOOGL',\n",
    "'GOOG',\n",
    "'AMZN',\n",
    "'AAL',\n",
    "'AMGN',\n",
    "'ADI',\n",
    "'ANSS',\n",
    "'AAPL',\n",
    "'AMAT',\n",
    "'ASML',\n",
    "'ADSK',\n",
    "'ADP',\n",
    "'BIDU',\n",
    "'BIIB',\n",
    "'BMRN',\n",
    "'BKNG',\n",
    "'AVGO',\n",
    "'CDNS',\n",
    "'CDW',\n",
    "'CERN',\n",
    "'CHTR',\n",
    "'CHKP',\n",
    "'CTAS',\n",
    "'CSCO',\n",
    "'CTXS',\n",
    "'CTSH',\n",
    "'CMCSA',\n",
    "'CPRT',\n",
    "'CSGP',\n",
    "'COST',\n",
    "'CSX',\n",
    "'DLTR',\n",
    "'EBAY',\n",
    "'EA',\n",
    "'EXC',\n",
    "'EXPE',\n",
    "'FB',\n",
    "'FAST',\n",
    "'FISV',\n",
    "'FOXA',\n",
    "'FOX',\n",
    "'GILD',\n",
    "'IDXX',\n",
    "'ILMN',\n",
    "'INCY',\n",
    "'INTC',\n",
    "'INTU',\n",
    "'ISRG',\n",
    "'JD',\n",
    "'KLAC',\n",
    "'KHC',\n",
    "'LRCX',\n",
    "'LBTYA',\n",
    "'LBTYK',\n",
    "'LULU',\n",
    "'MAR',\n",
    "'MXIM',\n",
    "'MELI',\n",
    "'MCHP',\n",
    "'MU',\n",
    "'MSFT',\n",
    "'MDLZ',\n",
    "'MNST',\n",
    "'NTAP',\n",
    "'NTES',\n",
    "'NFLX',\n",
    "'NVDA',\n",
    "'NXPI',\n",
    "'ORLY',\n",
    "'PCAR',\n",
    "'PAYX',\n",
    "'PYPL',\n",
    "'PEP',\n",
    "'QCOM',\n",
    "'REGN',\n",
    "'ROST',\n",
    "'SGEN',\n",
    "'SIRI',\n",
    "'SWKS',\n",
    "'SPLK',\n",
    "'SBUX',\n",
    "'SNPS',\n",
    "'TMUS',\n",
    "'TTWO',\n",
    "'TSLA',\n",
    "'TXN',\n",
    "'TCOM',\n",
    "'ULTA',\n",
    "'UAL',\n",
    "'VRSN',\n",
    "'VRSK',\n",
    "'VRTX',\n",
    "'WBA',\n",
    "'WDAY',\n",
    "'WDC',\n",
    "'WLTW',\n",
    "'XEL',\n",
    "'XLNX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a19b73a9703a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'top_100.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop_100_nasdaq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.save('top_100.npy',top_100_nasdaq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
